{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83e78f55-7c1a-4f88-b3c2-ac9478b2afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import traceback\n",
    "from heapq import heappop, heappush\n",
    "from pathlib import Path\n",
    "from textwrap import dedent\n",
    "from typing import Callable, Dict, Iterable, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from PIL import Image, ImageDraw\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "epsilon = 1e-3\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from TransPath_model import TransPathModel, GridData, TransPathLit\n",
    "from search_algorithms import Map, Node, SearchTreePQD, make_path, octile_distance, astar, astar_func, wastar\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0894c63-317a-49e3-b4c5-83f74ddce5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250/250 [00:07<00:00, 34.64it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './TransPath_data'\n",
    "model_path = './weights/gold_cf_model'\n",
    "mode = 'cf'\n",
    "accelerator = \"cuda\"\n",
    "devices = [6]\n",
    "batch_size = 256\n",
    "\n",
    "test_data = GridData(\n",
    "        path=f'{dataset_path}/test',\n",
    "        mode=mode\n",
    "    )\n",
    "\n",
    "dataloader = DataLoader(\n",
    "        test_data, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=False, \n",
    "        # num_workers=multiprocessing.cpu_count(), freezes jupyter notebook\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "eval_model = TransPathModel().to(torch.device(f'{accelerator}:{devices[-1]}'))\n",
    "eval_model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "eval_model.eval()\n",
    "predictions = []\n",
    "for map_design, start, goal, gt_hmap in tqdm(dataloader):\n",
    "    inputs = torch.cat([map_design, start + goal], dim=1) if mode in ('f', 'nastar') else torch.cat([map_design, goal], dim=1)\n",
    "    inputs = inputs.to(torch.device(f'{accelerator}:{devices[-1]}'))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = (eval_model(inputs) + 1) / 2\n",
    "\n",
    "    predictions.append(prediction)\n",
    "\n",
    "predictions = torch.cat(predictions).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc981055-78f9-4713-8c82-9c1a6945a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{dataset_path}/test/predicted_cf.npy', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0051f78b-3271-4a7f-af15-bda5c9d51f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250/250 [00:06<00:00, 36.51it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './TransPath_data'\n",
    "model_path = './weights/gold_h_model'\n",
    "mode = 'h'\n",
    "accelerator = \"cuda\"\n",
    "devices = [6]\n",
    "batch_size = 256\n",
    "\n",
    "test_data = GridData(\n",
    "        path=f'{dataset_path}/test',\n",
    "        mode=mode\n",
    "    )\n",
    "\n",
    "dataloader = DataLoader(\n",
    "        test_data, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=False, \n",
    "        # num_workers=multiprocessing.cpu_count(), freezes jupyter notebook\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "eval_model = TransPathModel().to(torch.device(f'{accelerator}:{devices[-1]}'))\n",
    "eval_model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "eval_model.eval()\n",
    "predictions = []\n",
    "for map_design, start, goal, gt_hmap in tqdm(dataloader):\n",
    "    inputs = torch.cat([map_design, start + goal], dim=1) if mode in ('f', 'nastar') else torch.cat([map_design, goal], dim=1)\n",
    "    inputs = inputs.to(torch.device(f'{accelerator}:{devices[-1]}'))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = (eval_model(inputs) + 1) / 2 * 64 * 64\n",
    "\n",
    "    predictions.append(prediction)\n",
    "\n",
    "predictions = torch.cat(predictions).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c913d3c-884b-4650-a7ec-dbd24ee6da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{dataset_path}/test/predicted_abs.npy', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ef10e46-7892-4d96-8972-6eb5e59272ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 42.66it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './TransPath_data/test'\n",
    "\n",
    "limit = 100\n",
    "\n",
    "cells = np.load(f'{dataset_path}/maps.npy', mmap_mode='c')[:limit]\n",
    "starts = np.load(f'{dataset_path}/starts.npy', mmap_mode='c')[:limit]\n",
    "goals = np.load(f'{dataset_path}/goals.npy', mmap_mode='c')[:limit]\n",
    "\n",
    "metrics = {'path_length' : [], 'expanded_nodes_num' : []}\n",
    "\n",
    "for i in tqdm(range(cells.shape[0])):\n",
    "    map = Map(cells[i, 0])\n",
    "    start_i, start_j = np.where(starts[i, 0])\n",
    "    start_i, start_j = start_i[0], start_j[0]\n",
    "    goal_i, goal_j = np.where(goals[i, 0])\n",
    "    goal_i, goal_j = goal_i[0], goal_j[0]\n",
    "    data = astar_func(map, start_i, start_j, goal_i, goal_j, octile_distance, SearchTreePQD)\n",
    "    assert data[0], draw(map, Node(start_i, start_j), Node(goal_i, goal_j))\n",
    "    path, length = make_path(data[1])\n",
    "    metrics['path_length'].append(length)\n",
    "    metrics['expanded_nodes_num'].append(len(data[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62c4b202-ab41-4fa8-8b4a-5c9ca2173c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2408627-d2b6-49de-8c6b-191bb1f21b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./vanilla_astar_octile_tie_break.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bef9103-f87c-45cc-a7b5-ffc5b128bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 111.62it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './TransPath_data/test'\n",
    "\n",
    "limit = 100\n",
    "\n",
    "cells = np.load(f'{dataset_path}/maps.npy', mmap_mode='c')[:limit]\n",
    "starts = np.load(f'{dataset_path}/starts.npy', mmap_mode='c')[:limit]\n",
    "goals = np.load(f'{dataset_path}/goals.npy', mmap_mode='c')[:limit]\n",
    "heuristics = np.load(f'{dataset_path}/predicted_abs.npy', mmap_mode='c')[:limit]\n",
    "\n",
    "metrics = {'path_length' : [], 'expanded_nodes_num' : []}\n",
    "\n",
    "for i in tqdm(range(cells.shape[0])):\n",
    "    map = Map(cells[i, 0])\n",
    "    start_i, start_j = np.where(starts[i, 0])\n",
    "    start_i, start_j = start_i[0], start_j[0]\n",
    "    goal_i, goal_j = np.where(goals[i, 0])\n",
    "    goal_i, goal_j = goal_i[0], goal_j[0]\n",
    "    data = astar(map, start_i, start_j, goal_i, goal_j, heuristics[i, 0], SearchTreePQD)\n",
    "    assert data[0], draw(map, Node(start_i, start_j), Node(goal_i, goal_j))\n",
    "    path, length = make_path(data[1])\n",
    "    metrics['path_length'].append(length)\n",
    "    metrics['expanded_nodes_num'].append(len(data[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbc929a3-f26a-4459-83b9-eb8a99e57284",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25299a05-90eb-4d25-ac41-ba8126ab96a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./vanilla_astar_hl.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a54f37a6-1806-4b73-aa6a-f31f265444b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 142.37it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './TransPath_data/test'\n",
    "\n",
    "limit = 100\n",
    "\n",
    "cells = np.load(f'{dataset_path}/maps.npy', mmap_mode='c')[:limit]\n",
    "starts = np.load(f'{dataset_path}/starts.npy', mmap_mode='c')[:limit]\n",
    "goals = np.load(f'{dataset_path}/goals.npy', mmap_mode='c')[:limit]\n",
    "heuristics = np.load(f'{dataset_path}/predicted_cf.npy', mmap_mode='c')[:limit]\n",
    "\n",
    "metrics = {'path_length' : [], 'expanded_nodes_num' : []}\n",
    "\n",
    "for i in tqdm(range(cells.shape[0])):\n",
    "    map = Map(cells[i, 0])\n",
    "    start_i, start_j = np.where(starts[i, 0])\n",
    "    start_i, start_j = start_i[0], start_j[0]\n",
    "    goal_i, goal_j = np.where(goals[i, 0])\n",
    "    goal_i, goal_j = goal_i[0], goal_j[0]\n",
    "    data = wastar(map, start_i, start_j, goal_i, goal_j, octile_distance, heuristics[i, 0], SearchTreePQD)\n",
    "    assert data[0], draw(map, Node(start_i, start_j), Node(goal_i, goal_j))\n",
    "    path, length = make_path(data[1])\n",
    "    metrics['path_length'].append(length)\n",
    "    metrics['expanded_nodes_num'].append(len(data[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a047a4e-4196-47d7-bf95-d66e3a576cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08fb8481-c964-47df-8eec-f8a9c14cacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./vanilla_wastar_cf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
